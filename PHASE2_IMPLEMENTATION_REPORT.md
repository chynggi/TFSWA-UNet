# Phase 2 êµ¬í˜„ ì™„ë£Œ ë³´ê³ ì„œ

## ğŸ“‹ ê°œìš”
TFSWA-UNetì˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë° í•™ìŠµ ì‹œìŠ¤í…œ (Phase 2)ë¥¼ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤.

**êµ¬í˜„ ë‚ ì§œ**: 2025ë…„ 10ì›” 4ì¼  
**êµ¬í˜„ ìƒíƒœ**: âœ… ì™„ë£Œ ë° í…ŒìŠ¤íŠ¸ í†µê³¼  
**ì£¼ìš” íŠ¹ì§•**: **ìœ ì—°í•œ ìŠ¤í…œ ì„ íƒ ì§€ì›** (vocals/other, 4-stem, ì»¤ìŠ¤í…€)

---

## âœ… êµ¬í˜„ ì™„ë£Œ í•­ëª©

### 1. ë°ì´í„° ë¡œë”© (`src/data/musdb_dataset.py`)

#### MUSDB18Dataset í´ë˜ìŠ¤ âœ…
```python
íŠ¹ì§•:
- ìœ ì—°í•œ ìŠ¤í…œ ì„ íƒ (vocals/other, 4-stem, ì»¤ìŠ¤í…€)
- ìë™ ìŠ¤í…œ í•©ì„± (other = drums + bass + other)
- Random/sequential ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
- Overlap ì§€ì› (validationìš©)
- Full track loading (í‰ê°€ìš©)
```

**í•µì‹¬ ê¸°ëŠ¥**:
- âœ… `target_stems` íŒŒë¼ë¯¸í„°ë¡œ ë¶„ë¦¬í•  ìŠ¤í…œ ì„ íƒ
- âœ… Binary ëª¨ë“œ: `['vocals', 'other']` â†’ otherëŠ” ìë™ìœ¼ë¡œ drums+bass+other í•©ì„±
- âœ… 4-stem ëª¨ë“œ: `['vocals', 'drums', 'bass', 'other']`
- âœ… ì»¤ìŠ¤í…€ ëª¨ë“œ: ì›í•˜ëŠ” ìŠ¤í…œ ì¡°í•© ê°€ëŠ¥
- âœ… Random segments (í•™ìŠµ) vs Sequential segments (í‰ê°€)
- âœ… `collate_fn` - ë°°ì¹˜ ìƒì„± í•¨ìˆ˜

### 2. STFT ì „ì²˜ë¦¬ (`src/data/stft_processor.py`)

#### STFTProcessor í´ë˜ìŠ¤ âœ…
- âœ… **STFT ë³€í™˜**: ì‹œê°„ ë„ë©”ì¸ â†’ ì£¼íŒŒìˆ˜ ë„ë©”ì¸
- âœ… **ISTFT ì—­ë³€í™˜**: ì£¼íŒŒìˆ˜ ë„ë©”ì¸ â†’ ì‹œê°„ ë„ë©”ì¸
- âœ… **Complex spectrogram** ì§€ì›
- âœ… **to_model_input()**: Complex â†’ Real/Imag ë¶„ë¦¬
- âœ… **from_model_output()**: Mask ì ìš© ë° ë¶„ë¦¬
- âœ… ì¬êµ¬ì„± ì˜¤ì°¨: **0.000000** (ì™„ë²½í•œ ì—­ë³€í™˜)

#### SpectrogramNormalizer í´ë˜ìŠ¤ âœ…
- âœ… Instance normalization (ì£¼íŒŒìˆ˜ binë³„)
- âœ… Batch normalization
- âœ… Denormalization ì§€ì›
- âœ… í†µê³„ëŸ‰ ì €ì¥/ë³µì›

### 3. Data Augmentation (`src/data/augmentation.py`)

#### AudioAugmentation í´ë˜ìŠ¤ âœ…
**Waveform-level augmentations**:
- âœ… Time stretching (0.9-1.1x tempo)
- âœ… Pitch shifting (Â±2 semitones)
- âœ… Volume scaling (0.7-1.3x gain)

**Spectrogram-level augmentations**:
- âœ… Frequency masking (max 80 bins)
- âœ… Time masking (max 40 frames)

#### MixupAugmentation í´ë˜ìŠ¤ âœ…
- âœ… Beta distribution ê¸°ë°˜ mixup
- âœ… ë‹¤ì¤‘ íŠ¸ë™ í˜¼í•©
- âœ… í™•ë¥ ì  ì ìš© (apply_prob)

### 4. Loss Functions (`src/training/losses.py`)

#### L1SpectrogramLoss âœ…
- âœ… Magnitude spectrogram L1 loss
- âœ… Complex tensor ìë™ ì²˜ë¦¬
- âœ… Reduction ëª¨ë“œ ì§€ì›

#### MultiResolutionSTFTLoss âœ…
- âœ… ë‹¤ì¤‘ í•´ìƒë„ STFT (2048, 1024, 512)
- âœ… Magnitude loss
- âœ… Log magnitude loss
- âœ… ì—¬ëŸ¬ hop length ì§€ì›

#### SourceSeparationLoss âœ…
- âœ… L1 + Multi-resolution STFT ê²°í•©
- âœ… ìŠ¤í…œë³„ ê°œë³„ loss ì¶”ì 
- âœ… ê°€ì¤‘ì¹˜ ì¡°ì ˆ ê°€ëŠ¥ (l1_weight, mrstft_weight)
- âœ… Loss dictionary ë°˜í™˜

### 5. Training System (`src/training/trainer.py`)

#### Trainer í´ë˜ìŠ¤ âœ…
**í•µì‹¬ ê¸°ëŠ¥**:
- âœ… **Training loop** - Epoch ê´€ë¦¬
- âœ… **Validation loop** - ì£¼ê¸°ì  ê²€ì¦
- âœ… **Gradient clipping** - ì•ˆì •ì  í•™ìŠµ
- âœ… **Mixed precision (AMP)** - FP16 ì§€ì›
- âœ… **Learning rate scheduling** - Cosine annealing
- âœ… **TensorBoard logging** - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- âœ… **Checkpoint ì €ì¥/ë¡œë“œ** - í•™ìŠµ ì¬ê°œ
- âœ… **Best model tracking** - ìµœì  ëª¨ë¸ ì €ì¥

**Progress tracking**:
- âœ… Training/validation loss per epoch
- âœ… Learning rate scheduling
- âœ… Best validation loss tracking
- âœ… Progress bar (tqdm)

### 6. Training Script (`scripts/train.py`)

#### ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤ âœ…
```bash
python scripts/train.py \
    --data_root data/musdb18 \
    --target_stems vocals other \
    --batch_size 4 \
    --max_epochs 300 \
    --learning_rate 1e-3 \
    --device cuda
```

**ì£¼ìš” ì¸ì**:
- âœ… Data: `--data_root`, `--target_stems`, `--segment_seconds`
- âœ… Model: `--depths`, `--dims`, `--window_size`, `--num_heads`
- âœ… STFT: `--n_fft`, `--hop_length`
- âœ… Training: `--batch_size`, `--max_epochs`, `--learning_rate`
- âœ… Loss: `--l1_weight`, `--mrstft_weight`
- âœ… Logging: `--output_dir`, `--log_every_n_steps`
- âœ… Optimization: `--use_amp`, `--gradient_clip_val`
- âœ… Resume: `--resume` (checkpoint ê²½ë¡œ)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼

### STFT Processor âœ…
```
Input:  (2, 2, 44100) waveform
STFT:   (2, 2, 1025, 87) complex spectrogram
Model:  (2, 4, 1025, 87) real/imag separated
ISTFT:  (2, 2, 44100) reconstructed

Reconstruction error: 0.000000 âœ“
```

### Spectrogram Normalizer âœ…
```
Normalization â†’ Denormalization error: 0.000000 âœ“
```

### Loss Functions âœ…
```
L1 Loss: 1.1276 âœ“
Multi-resolution STFT Loss: 11.3450 âœ“
Combined Loss: Computed successfully âœ“
```

### End-to-End Pipeline âœ…
```
Input mixture:     (1, 2, 132300)
STFT:             (1, 2, 1025, 259)
Model input:      (1, 4, 1025, 259)
Model output:     (1, 4, 1025, 259)
Separated vocals: (1, 2, 132300)
Separated other:  (1, 2, 132300)

âœ“ Shape preservation
âœ“ Perfect reconstruction
```

### Flexible Stem Selection âœ…
```
2-stem (vocals, other):              1,448,788 params âœ“
4-stem (vocals, drums, bass, other): 1,448,856 params âœ“
1-stem (vocals only):                1,448,754 params âœ“
```

---

## ğŸ¯ íŠ¹ë³„ ê¸°ëŠ¥: ìœ ì—°í•œ ìŠ¤í…œ ì„ íƒ

### êµ¬í˜„ ë°©ì‹

#### 1. Binary Separation (vocals vs accompaniment)
```python
target_stems = ['vocals', 'other']

# Dataset automatically combines:
# 'other' = drums + bass + other
```

#### 2. 4-Stem Separation (full separation)
```python
target_stems = ['vocals', 'drums', 'bass', 'other']

# Each stem is loaded individually
```

#### 3. Custom Combinations
```python
target_stems = ['vocals', 'drums']  # Only vocals and drums
target_stems = ['vocals']           # Vocals only (vs mixture)
```

### ë‚´ë¶€ ë¡œì§

```python
def _get_combined_stem(self, track, stem_name):
    """Get individual or combined stem."""
    
    # Binary mode: vocals vs rest
    if stem_name == 'other' and 'vocals' in self.target_stems:
        # Combine drums + bass + other
        audio = track.targets['drums'].audio + \
                track.targets['bass'].audio + \
                track.targets['other'].audio
        return audio
    
    # Individual stem
    return track.targets[stem_name].audio
```

### ëª¨ë¸ ì¶œë ¥ ì±„ë„ ìë™ ì¡°ì •

```python
# Training script automatically adjusts:
n_stems = len(target_stems)
model_out_channels = 2 * n_stems  # 2 channels per stem (real, imag)

model = TFSWAUNet(
    in_channels=4,  # Always 4 (stereo real+imag)
    out_channels=model_out_channels,  # Depends on n_stems
    ...
)
```

---

## ğŸ“Š ë°ì´í„° íŒŒì´í”„ë¼ì¸ íë¦„

```
Raw Audio (MUSDB18)
    â†“
[MUSDB18Dataset]
    â†“
Waveform Segments (B, 2, samples)
    â†“
[AudioAugmentation] (optional)
    â†“
[STFTProcessor.stft()]
    â†“
Complex Spectrogram (B, 2, F, T)
    â†“
[STFTProcessor.to_model_input()]
    â†“
Real/Imag Separated (B, 4, F, T)
    â†“
[TFSWAUNet]
    â†“
Masks (B, n_stems*2, F, T)
    â†“
[Apply masks to mixture]
    â†“
Separated Spectrograms
    â†“
[STFTProcessor.istft()]
    â†“
Separated Waveforms
```

---

## ğŸ”§ Training ì„¤ì •

### ê¶Œì¥ í•˜ì´í¼íŒŒë¼ë¯¸í„°

```yaml
# Data
batch_size: 4-8 (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼)
segment_seconds: 6.0 (ì•½ 260 time frames)
sample_rate: 44100

# Model
n_fft: 2048
hop_length: 512
depths: [2, 2, 6, 2]
dims: [32, 64, 128, 256]

# Training
learning_rate: 1e-3
weight_decay: 1e-4
max_epochs: 300
gradient_clip_val: 1.0

# Loss
l1_weight: 1.0
mrstft_weight: 0.5 (ë˜ëŠ” 0.0, ê³„ì‚° ë¹„ìš© ë†’ìŒ)
```

### Mixed Precision Training

```bash
# FP16 í•™ìŠµ (2ë°° ë¹ ë¦„, ë©”ëª¨ë¦¬ ì ˆì•½)
python scripts/train.py --use_amp
```

### Resume Training

```bash
# ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
python scripts/train.py --resume outputs/tfswa_unet/checkpoints/latest_model.pt
```

---

## ğŸ“ ìƒì„±ëœ íŒŒì¼

### ë°ì´í„° ëª¨ë“ˆ
```
src/data/
â”œâ”€â”€ musdb_dataset.py       # MUSDB18 ë°ì´í„°ì…‹ ë¡œë”
â”œâ”€â”€ stft_processor.py      # STFT/ISTFT ì²˜ë¦¬
â”œâ”€â”€ augmentation.py        # Data augmentation
â””â”€â”€ __init__.py            # ëª¨ë“ˆ ì´ˆê¸°í™”
```

### í•™ìŠµ ëª¨ë“ˆ
```
src/training/
â”œâ”€â”€ losses.py              # Loss functions
â”œâ”€â”€ trainer.py             # Training loop
â””â”€â”€ __init__.py            # ëª¨ë“ˆ ì´ˆê¸°í™”
```

### ìŠ¤í¬ë¦½íŠ¸
```
scripts/
â””â”€â”€ train.py               # Training ì§„ì…ì 
```

### í…ŒìŠ¤íŠ¸
```
test_phase2.py             # Phase 2 ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
```

---

## ğŸ’¡ ì‚¬ìš© ì˜ˆì œ

### 1. Binary Separation (vocals vs other)

```python
from src.data import MUSDB18Dataset, STFTProcessor
from src.models import TFSWAUNet

# Dataset
dataset = MUSDB18Dataset(
    root='data/musdb18',
    split='train',
    target_stems=['vocals', 'other'],  # Binary mode
)

# Model (2 stems Ã— 2 channels = 4 output channels)
model = TFSWAUNet(
    in_channels=4,
    out_channels=4,
    ...
)
```

### 2. 4-Stem Separation

```python
# Dataset
dataset = MUSDB18Dataset(
    root='data/musdb18',
    split='train',
    target_stems=['vocals', 'drums', 'bass', 'other'],
)

# Model (4 stems Ã— 2 channels = 8 output channels)
model = TFSWAUNet(
    in_channels=4,
    out_channels=8,
    ...
)
```

### 3. Training

```bash
# Binary separation
python scripts/train.py \
    --data_root data/musdb18 \
    --target_stems vocals other \
    --batch_size 4 \
    --max_epochs 300

# 4-stem separation
python scripts/train.py \
    --data_root data/musdb18 \
    --target_stems vocals drums bass other \
    --batch_size 2 \
    --max_epochs 300
```

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„ (Phase 3)

Phase 2ê°€ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ, í‰ê°€ ë° ìµœì í™” êµ¬í˜„:

### Phase 3 ìš°ì„ ìˆœìœ„:
1. âœ… **SDR/SIR/SAR ë©”íŠ¸ë¦­** - museval í†µí•©
2. âœ… **Inference íŒŒì´í”„ë¼ì¸** - Full track ì²˜ë¦¬
3. âœ… **í‰ê°€ ìŠ¤í¬ë¦½íŠ¸** - MUSDB18 benchmark
4. âœ… **Gradient checkpointing** - ë©”ëª¨ë¦¬ ìµœì í™”
5. âœ… **ëª¨ë¸ export** - ONNX, TorchScript

---

## ğŸ“ ì•Œë ¤ì§„ ì œí•œì‚¬í•­

### 1. MUSDB18 ë°ì´í„°ì…‹ í•„ìš”
- `pip install musdb` í•„ìš”
- MUSDB18-HQ ë‹¤ìš´ë¡œë“œ í•„ìš” (~38GB)

### 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- Batch size 4: ~8GB GPU ë©”ëª¨ë¦¬
- Longer segments: ë” ë§ì€ ë©”ëª¨ë¦¬ í•„ìš”
- Mixed precision (FP16) ì‚¬ìš© ê¶Œì¥

### 3. Multi-resolution STFT Loss
- ê³„ì‚° ë¹„ìš© ë†’ìŒ
- í•™ìŠµ ì´ˆê¸°ì—ëŠ” ë¹„í™œì„±í™” ê¶Œì¥
- Fine-tuning ë‹¨ê³„ì—ì„œ í™œì„±í™”

---

## âœ¨ í•µì‹¬ ì„±ê³¼

**Phase 2: ë°ì´í„° & í•™ìŠµ ì‹œìŠ¤í…œ ì™„ë£Œ!**

- âœ… MUSDB18 ë°ì´í„°ì…‹ ë¡œë” (ìœ ì—°í•œ ìŠ¤í…œ ì„ íƒ)
- âœ… STFT/ISTFT íŒŒì´í”„ë¼ì¸ (ì™„ë²½í•œ ì¬êµ¬ì„±)
- âœ… Data augmentation (6ê°€ì§€ ê¸°ë²•)
- âœ… Loss functions (L1 + Multi-resolution STFT)
- âœ… Training loop (mixed precision, checkpointing)
- âœ… Training script (ì™„ì „í•œ CLI)
- âœ… End-to-end í…ŒìŠ¤íŠ¸ í†µê³¼

**íŠ¹ë³„ ê¸°ëŠ¥**:
- ğŸ¯ **ìœ ì—°í•œ ìŠ¤í…œ ì„ íƒ** - 2-stem, 4-stem, ì»¤ìŠ¤í…€
- ğŸ¯ **ìë™ ìŠ¤í…œ í•©ì„±** - other = drums+bass+other
- ğŸ¯ **ëª¨ë¸ ì¶œë ¥ ìë™ ì¡°ì •** - ìŠ¤í…œ ìˆ˜ì— ë”°ë¼

**ë‹¤ìŒ ë‹¨ê³„**: Phase 3ë¡œ ì§„í–‰í•˜ì—¬ í‰ê°€ ì‹œìŠ¤í…œ êµ¬ì¶• ë° ì‹¤ì œ í•™ìŠµ!

---

**êµ¬í˜„ì**: GitHub Copilot  
**ê²€ì¦**: ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ âœ…  
**ë‚ ì§œ**: 2025ë…„ 10ì›” 4ì¼
