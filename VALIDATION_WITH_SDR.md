# Validation with SDR Metrics

## Overview

TFSWA-UNet í•™ìŠµ ê³¼ì •ì—ì„œ ì‹¤ì œ ìŒì› ë¶„ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê³  SDR(Signal-to-Distortion Ratio) ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

## Features

### ğŸ¯ Real Source Separation Evaluation
- **ì‹¤ì œ ìŒì› ë¶„ë¦¬**: ì†ì‹¤ í•¨ìˆ˜ ê¸°ë°˜ í‰ê°€ê°€ ì•„ë‹Œ, ì‹¤ì œë¡œ ìŒì›ì„ ë¶„ë¦¬í•˜ì—¬ í‰ê°€
- **SDR ì§€í‘œ**: ì—…ê³„ í‘œì¤€ SDR(Signal-to-Distortion Ratio) ë° SI-SDR ê³„ì‚°
- **Validation Set**: MUSDB18 validation subsetì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€
- **íš¨ìœ¨ì ì¸ í‰ê°€**: ì „ì²´ íŠ¸ë™ ëŒ€ì‹  ì¼ë¶€ íŠ¸ë™ë§Œ í‰ê°€í•˜ì—¬ ì‹œê°„ ì ˆì•½

### ğŸ“Š Metrics Computed

1. **SDR (Signal-to-Distortion Ratio)**
   - ì „ì²´ ë¶„ë¦¬ í’ˆì§ˆ ì¸¡ì •
   - ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ (ë‹¨ìœ„: dB)

2. **SI-SDR (Scale-Invariant SDR)**
   - ìŠ¤ì¼€ì¼ ë¶ˆë³€ SDR
   - ë³¼ë¥¨ ì°¨ì´ì— ì˜í–¥ë°›ì§€ ì•ŠìŒ

3. **Per-Stem Metrics**
   - `vocals_sdr`: Vocals ë¶„ë¦¬ SDR
   - `vocals_si_sdr`: Vocals ë¶„ë¦¬ SI-SDR
   - `other_sdr`: Other (accompaniment) ë¶„ë¦¬ SDR
   - `other_si_sdr`: Other ë¶„ë¦¬ SI-SDR

4. **Overall Average**
   - `avg_sdr`: ëª¨ë“  stemì˜ í‰ê·  SDR

## Usage

### Basic Training with SDR Evaluation (ê¸°ë³¸ê°’)

SDR í‰ê°€ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

```bash
python scripts/train.py \
    --data_root /path/to/musdb18 \
    --eval_num_tracks 5 \
    --val_every_n_epochs 5
```

**SDR í‰ê°€ ì‹œì **: 
- ì²« ë²ˆì§¸ validation (epoch 5)
- ì´í›„ 5ë²ˆì§¸ validationë§ˆë‹¤ (epoch 25, 50, 75, 100...)

### Disable SDR Evaluation (Faster)

ì†ì‹¤ í•¨ìˆ˜ ê¸°ë°˜ í‰ê°€ë§Œ ìˆ˜í–‰:

```bash
python scripts/train.py \
    --data_root /path/to/musdb18 \
    --no_eval_sdr
```

### Adjust Evaluation Frequency

SDR í‰ê°€ëŠ” ê³„ì‚° ë¹„ìš©ì´ ë†’ìœ¼ë¯€ë¡œ, ì²« ë²ˆì§¸ validationê³¼ ì´í›„ 5ë²ˆì§¸ validationë§ˆë‹¤ ìˆ˜í–‰ë©ë‹ˆë‹¤:

```bash
python scripts/train.py \
    --val_every_n_epochs 5
    # Validation: epochs 5, 10, 15, 20, 25, 30...
    # SDR í‰ê°€: epochs 5 (val #1), 25 (val #5), 50 (val #10), 75 (val #15)...
```

ì²« validationì—ì„œë„ SDR í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ì—¬ ì´ˆê¸° ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Low VRAM Settings

ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ê²½ìš°:

```bash
python scripts/train.py \
    --eval_num_tracks 3 \
    --segment_seconds 3.0 \
    --batch_size 1
```

## Configuration Options

### Command Line Arguments

| Argument | Default | Description |
|----------|---------|-------------|
| `--eval_sdr` | `True` | SDR í‰ê°€ í™œì„±í™” |
| `--no_eval_sdr` | - | SDR í‰ê°€ ë¹„í™œì„±í™” |
| `--eval_num_tracks` | `5` | í‰ê°€í•  validation íŠ¸ë™ ìˆ˜ |
| `--val_every_n_epochs` | `5` | Validation ì£¼ê¸° (epoch) |

### Programmatic Configuration

```python
trainer = Trainer(
    model=model,
    optimizer=optimizer,
    # ... other args ...
    eval_sdr=True,              # Enable SDR evaluation
    eval_num_tracks=5,          # Evaluate on 5 tracks
)
```

## How It Works

### 1. Overlap-Add Inference

ê¸´ ì˜¤ë””ì˜¤ íŠ¸ë™ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ overlap-add ë°©ì‹ ì‚¬ìš©:

```python
# 10ì´ˆ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„í• 
segment_length = 10.0 seconds
overlap = 50%  # 5ì´ˆ overlap

# Hann windowë¡œ smooth blending
window = torch.hann_window(segment_samples)
```

### 2. Full Track Separation

```python
def _separate_track(mixture):
    # 1. Segment audio
    # 2. Process each segment with model
    # 3. Apply masks to mixture spectrogram
    # 4. ISTFT to reconstruct audio
    # 5. Overlap-add with windowing
    return separated_stems
```

### 3. SDR Computation

```python
# Ground truth stems
references = {
    'vocals': vocals_audio,
    'other': drums + bass + other
}

# Compute SDR for each stem
for stem_name in ['vocals', 'other']:
    sdr_value = sdr(estimate, reference)
    si_sdr_value = si_sdr(estimate, reference)
```

## Output Examples

### During Training

```
Epoch 25/300 - Train losses:
  l1_vocals: 0.0547
  l1_other: 0.0621
  total_loss: 0.0584

Performing SDR evaluation...
SDR Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:23<00:00, 16.7s/it, avg_SDR=4.23dB]

SDR Metrics:
  vocals_sdr: 5.124 dB
  vocals_si_sdr: 4.987 dB
  other_sdr: 3.341 dB
  other_si_sdr: 3.198 dB
  avg_sdr: 4.233 dB

New best model with SDR: 4.233 dB
```

### TensorBoard Logs

SDR ì§€í‘œê°€ ìë™ìœ¼ë¡œ TensorBoardì— ë¡œê¹…ë©ë‹ˆë‹¤:

```
sdr/vocals_sdr
sdr/vocals_si_sdr
sdr/other_sdr
sdr/other_si_sdr
sdr/avg_sdr
```

## Performance Considerations

### Evaluation Time

| Tracks | Segment | Time (GPU) |
|--------|---------|------------|
| 3 tracks | 10s | ~1 min |
| 5 tracks | 10s | ~1.5 min |
| 10 tracks | 10s | ~3 min |

### Memory Usage

- **Peak Memory**: ~4-6GB VRAM (depends on track length)
- **Gradient-free**: `@torch.no_grad()` ì‚¬ìš©
- **Mixed Precision**: AMP ì§€ì›ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½

### Best Practices

1. **ì ì ˆí•œ íŠ¸ë™ ìˆ˜**: 5ê°œ íŠ¸ë™ì´ ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜•ì 
2. **í‰ê°€ ì£¼ê¸°**: ì´ˆê¸°ì—ëŠ” ìì£¼, í›„ë°˜ì—ëŠ” ëœ ìì£¼ í‰ê°€
3. **Best Model**: SDR ê¸°ë°˜ìœ¼ë¡œ best model ì €ì¥

## Model Selection Strategy

### Loss-based vs SDR-based

```python
# Every 5 epochs: Loss-based validation (fast)
if (epoch + 1) % 5 == 0:
    val_loss = validate()  # ~10 seconds
    
    # First validation and every 5th validation: SDR evaluation
    val_count = (epoch + 1) // 5  # validation number
    if val_count == 1 or val_count % 5 == 0:
        sdr_metrics = evaluate_sdr()  # ~90 seconds
        # Use avg_sdr for best model selection
```

**ì‹¤ì œ ì‹¤í–‰**:
- Epoch 5 (val #1): Loss + SDR âœ“
- Epoch 10 (val #2): Loss only
- Epoch 15 (val #3): Loss only
- Epoch 20 (val #4): Loss only
- Epoch 25 (val #5): Loss + SDR âœ“
- Epoch 30 (val #6): Loss only
- ...

### Best Model Criteria

- **Primary**: Average SDR across all stems
- **Fallback**: Validation loss if SDR not available
- **Direction**: Higher SDR = Better (stored as negative for consistency)

## Troubleshooting

### Out of Memory

```bash
# Reduce evaluation tracks
--eval_num_tracks 3

# Use shorter segments
--segment_seconds 3.0

# Disable SDR evaluation temporarily
--no_eval_sdr
```

### Slow Evaluation

```bash
# Reduce number of tracks
--eval_num_tracks 3

# Increase validation interval
--val_every_n_epochs 10
# SDR will run every 50 epochs
```

### Inconsistent Results

- **Solution 1**: Increase `eval_num_tracks` for more stable metrics
- **Solution 2**: Use SI-SDR which is scale-invariant
- **Solution 3**: Evaluate on full test set after training

## Advanced Usage

### Custom Evaluation Tracks

validation datasetì˜ íŠ¹ì • íŠ¸ë™ë§Œ í‰ê°€í•˜ë ¤ë©´:

```python
# Modify in trainer.py
eval_tracks = val_dataset.tracks[indices]  # Custom track selection
```

### Frame-wise SDR

ê¸´ íŠ¸ë™ì˜ í”„ë ˆì„ë³„ SDRì„ ê³„ì‚°í•˜ë ¤ë©´:

```python
from src.evaluation.metrics import MetricsCalculator

calculator = MetricsCalculator(
    sample_rate=44100,
    segment_length=44100 * 10  # 10-second frames
)

metrics = calculator.compute(estimate, reference, compute_all=True)
```

## Expected Performance

### Target Metrics (MUSDB18)

| Metric | Target | SOTA |
|--------|--------|------|
| Vocals SDR | >8.0 dB | 9.16 dB |
| Other SDR | >12.0 dB | 14.0 dB |
| Average SDR | >10.0 dB | 11.5 dB |

### Training Progress

Typical SDR progression during training:

```
Epoch 0-25:   avg_sdr ~ 2-4 dB   (ì´ˆê¸° í•™ìŠµ)
Epoch 25-100: avg_sdr ~ 4-7 dB   (ë¹ ë¥¸ í–¥ìƒ)
Epoch 100-200: avg_sdr ~ 7-9 dB  (ì•ˆì •í™”)
Epoch 200-300: avg_sdr ~ 9-10 dB (ë¯¸ì„¸ ì¡°ì •)
```

## References

1. **BSS Eval**: Vincent, E., et al. "Performance measurement in blind audio source separation." IEEE TASLP, 2006.
2. **SI-SDR**: Le Roux, J., et al. "SDR â€“ half-baked or well done?" ICASSP, 2019.
3. **MUSDB18**: Rafii, Z., et al. "MUSDB18 - a corpus for music separation." 2017.

## See Also

- [IMPLEMENTATION_CHECKLIST.md](IMPLEMENTATION_CHECKLIST.md) - Implementation status
- [src/evaluation/metrics.py](src/evaluation/metrics.py) - Metrics implementation
- [src/evaluation/evaluator.py](src/evaluation/evaluator.py) - Full evaluation system
